{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e22badf-6c2f-40f6-aaf0-78cbe1fd35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5611b73-d116-4dfc-8499-f2a5c7c08e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_selenuim():\n",
    "    \"\"\"\n",
    "    this function starts selenuim web driver only once to make the script faster\n",
    "    and returns an object of chrome driver\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions() \n",
    "    options.add_argument('--ignore-certificate-errors') \n",
    "    options.add_argument('--incognito') \n",
    "    # options.add_argument('--headless') \n",
    "    options.add_argument('window-size=50x50');\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(800, 800)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c88b3013-a542-481b-865b-f89e51da1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page_selenuim(link):\n",
    "    driver.get(link);\n",
    "    return BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db1400b3-1990-42e9-9bef-8f07ca1413c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page_requests(link):\n",
    "    page = requests.get(link)\n",
    "    src = page.content\n",
    "    soup = BeautifulSoup(src,\"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8410231-3e82-48f5-b082-39a5e1642328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_results_num(link):\n",
    "    pure_page = load_page_selenuim(link)\n",
    "    return int(pure_page.find(\"strong\").text.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0b7734f-db07-4b6b-9c41-9d6532f04e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_job_page_scraping(link):\n",
    "\n",
    "    soup = load_page_selenuim(\"https://wuzzuf.net\"+link)\n",
    "\n",
    "    section1 = soup.find(\"section\",{\"class\":\"css-dy1y6u\"})\n",
    "    try:\n",
    "        title = section1.find(\"h1\").text\n",
    "    except:\n",
    "        title = section1.find(\"h1\",{\"class\":\"css-f9uh36\"}).text\n",
    "        \n",
    "    try :\n",
    "        company = section1.find(\"a\",{\"class\":\"css-p7pghv\"}).text\n",
    "        c_link = section1.find(\"a\",{\"class\":\"css-p7pghv\"}).attrs[\"href\"]\n",
    "    except :\n",
    "        company = \"Confidential Company\"\n",
    "        c_link = \"Confidential Company\"\n",
    "        \n",
    "            \n",
    "    post = section1.find(\"span\",{\"class\":\"css-182mrdn\"}).text\n",
    "    job_title.append(title)\n",
    "    company_name.append(company)\n",
    "    company_link.append(c_link)\n",
    "    posted.append(post)\n",
    "    \n",
    "    \n",
    "    section2 = soup.find(\"section\",{\"class\":\"css-3kx5e2\"})\n",
    "    job_details = section2.find_all(\"span\",{\"class\":\"css-4xky9y\"})\n",
    "    \n",
    "    experience.append(job_details[0].text)\n",
    "    career_level.append(job_details[1].text)\n",
    "    education_level.append(job_details[2].text)\n",
    "    \n",
    "    if(len(job_details) == 4):\n",
    "        salary.append(job_details[3].text)\n",
    "    else:\n",
    "        salary.append(job_details[4].text)\n",
    "        \n",
    "    \n",
    "    \n",
    "    categories = section2.find(\"div\",{\"class\":\"css-13sf2ik\"}).find_all(\"span\",{\"class\":\"css-158icaa\"})\n",
    "    skills = section2.find(\"div\",{\"class\":\"css-s2o0yh\"}).find_all(\"span\",{\"class\":\"css-158icaa\"})\n",
    "    categories_text = \"\"\n",
    "    skill_text = \"\"\n",
    "    for cat in categories :\n",
    "        categories_text += cat.text+\" | \"\n",
    "    for skill in skills:\n",
    "        skill_text += skill.text+\" | \"\n",
    "        \n",
    "    job_category.append(categories_text[:-3])\n",
    "    skills_and_tools.append(skill_text[:-3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fff2991-f9a1-42b4-8349-fa562faf8fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_full_scrapping(search):\n",
    "    global jobs_num\n",
    "    jobs_num = find_results_num(f\"https://wuzzuf.net/search/jobs/?a=hpb%7Cspbg&q={search}\")\n",
    "    print(f\"{jobs_num} jobs results has been found\")\n",
    "    global count \n",
    "    count = 0\n",
    "    for i in tqdm(range(0,(jobs_num //15)+1)):\n",
    "        try:\n",
    "            soup = load_page_requests(f\"https://wuzzuf.net/search/jobs/?a=hpb%7Cspbg&q={search}&start={i}\")\n",
    "        except:\n",
    "            continue\n",
    "        l = soup.find_all(\"h2\",{\"class\":\"css-m604qf\"})\n",
    "        loc = soup.find_all(\"div\",{\"class\":\"css-d7j1kk\"})\n",
    "        for lo in loc :\n",
    "            location.append(lo.find(\"span\").text)\n",
    "        for li in l :\n",
    "            link = li.find(\"a\").attrs['href']\n",
    "            links.append(\"https://wuzzuf.net\"+link)\n",
    "            do_job_page_scraping(link)\n",
    "            driver.refresh()\n",
    "            count+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "921eeae5-dec6-4111-9d83-b831d744cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(search):\n",
    "    data = {\n",
    "        \"Job title\": job_title, \n",
    "        \"Company name\" :company_name, \n",
    "        \"Location\":location , \n",
    "        \"posted\" : posted, \n",
    "        \"Experience\" : experience, \n",
    "        \"Career Level\" : career_level,\n",
    "        \"Education Level\" : education_level,\n",
    "        \"Salary\" : salary,\n",
    "        \"Job Categories\":job_category ,\n",
    "        \"Skills and Tools\":skills_and_tools,\n",
    "        \"Job link\" : links , \n",
    "        \"Company Link\" : company_link\n",
    "    }\n",
    "    \n",
    "    final_data = pd.DataFrame(data)\n",
    "    final_data.to_csv(f\"Wuzzuf_{search}.csv\",index=False)\n",
    "    print(\"website scrapping done succesfully\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"____________________Script Summary____________________\")\n",
    "    print(f\" {count} jobs scrapped\")\n",
    "    print(f\" {jobs_num - count} jobs not scrapped\")\n",
    "    print(f\" The data has been saved in Wuzzuf_{search}.csv\") \n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa40947a-8faa-4232-89b4-182acf2987df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_error(search,error):\n",
    "    data = {\n",
    "        \"Job title\": job_title[0:count], \n",
    "        \"Company name\" :company_name[0:count], \n",
    "        \"Location\":location[0:count] , \n",
    "        \"posted\" : posted[0:count], \n",
    "        \"Experience\" : experience[0:count], \n",
    "        \"Career Level\" : career_level[0:count],\n",
    "        \"Education Level\" : education_level[0:count],\n",
    "        \"Salary\" : salary[0:count],\n",
    "        \"Job Categories\":job_category[0:count] ,\n",
    "        \"Skills and Tools\":skills_and_tools[0:count],\n",
    "        \"Job link\" : links[0:count] , \n",
    "        \"Company Link\" : company_link[0:count]\n",
    "    }\n",
    "    \n",
    "    final_data_error = pd.DataFrame(data)\n",
    "    final_data_error.to_csv(f\"Wuzzuf_{search}.csv\",index=False)\n",
    "    print(\"Error has occured !\")\n",
    "    print(error)\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"____________________Script Summary___________________\")\n",
    "    print(f\" {count} jobs scrapped \")\n",
    "    print(f\" {jobs_num - count} jobs not scrapped\")\n",
    "    print(f\" The data has been saved in Wuzzuf_{search}.csv\") \n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70499332-0c05-4177-9639-77b759ff87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_script():\n",
    "    print(\"Wuzzuf.net website scrapping\")\n",
    "    search = input(\"type the search keyword you want to scrap -if you want to scrap all the website data press enter - :\")\n",
    "    global driver\n",
    "    driver = start_selenuim()\n",
    "    \n",
    "    \n",
    "    global links ,location,job_title,company_name,company_link,location,posted,details,experience,career_level,education_level ,salary ,job_category ,skills_and_tools \n",
    "    \n",
    "    links = []\n",
    "    job_title = []\n",
    "    company_name = []\n",
    "    company_link = []\n",
    "    location = []\n",
    "    posted = []\n",
    "    details = []\n",
    "    experience = []\n",
    "    career_level = []\n",
    "    education_level = []\n",
    "    salary = []\n",
    "    job_category = []\n",
    "    skills_and_tools = [] \n",
    "    \n",
    "    try:\n",
    "        do_full_scrapping(search)\n",
    "        save_data(search)\n",
    "    except Exception as error :\n",
    "        save_data_error(search,error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd8064a4-b10d-4f0d-bbc1-f723db43e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wuzzuf.net website scrapping\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "type the search keyword you want to scrap -if you want to scrap all the website data press enter - : python1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 jobs results has been found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error has occured !\n",
      "Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=106.0.5249.119)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tOrdinal0 [0x004C1ED3+2236115]\n",
      "\tOrdinal0 [0x004592F1+1807089]\n",
      "\tOrdinal0 [0x003666FD+812797]\n",
      "\tOrdinal0 [0x0034DFFA+712698]\n",
      "\tOrdinal0 [0x003B506B+1134699]\n",
      "\tOrdinal0 [0x003C514A+1200458]\n",
      "\tOrdinal0 [0x003B18A6+1120422]\n",
      "\tOrdinal0 [0x0038A73D+960317]\n",
      "\tOrdinal0 [0x0038B71F+964383]\n",
      "\tGetHandleVerifier [0x0076E7E2+2743074]\n",
      "\tGetHandleVerifier [0x007608D4+2685972]\n",
      "\tGetHandleVerifier [0x00552BAA+532202]\n",
      "\tGetHandleVerifier [0x00551990+527568]\n",
      "\tOrdinal0 [0x0046080C+1837068]\n",
      "\tOrdinal0 [0x00464CD8+1854680]\n",
      "\tOrdinal0 [0x00464DC5+1854917]\n",
      "\tOrdinal0 [0x0046ED64+1895780]\n",
      "\tBaseThreadInitThunk [0x7676FA29+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77CC7B5E+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77CC7B2E+238]\n",
      "\n",
      "------------------------------------------------------\n",
      "____________________Script Summary___________________\n",
      " 0 jobs scrapped \n",
      " 25 jobs not scrapped\n",
      " The data has been saved in Wuzzuf_python1.csv\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ae7cd-addd-415e-86f5-14c9ab156e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
